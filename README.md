# Data Acquisition-Web Crawler Using Scrapy

Scrapy is an open source and collaborative framework for extracting the data from various websites

For installing scrapy on your machine use ```pip install scrapy```.

While using **Scrapy**, the first question that comes to our mind is regarding **Spiders**.

Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass `Spider` and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data.

